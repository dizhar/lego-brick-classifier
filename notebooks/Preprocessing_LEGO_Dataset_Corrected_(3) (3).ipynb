{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LEGO Dataset Preprocessing - Complete Workflow\n",
        "\n",
        "This notebook:\n",
        "1. Takes original pile images from `pile_of_augmented_lego_pieces/images`\n",
        "2. **Creates augmented versions of the pile images** (for better pile detection)\n",
        "3. Crops individual LEGO pieces from the original pile images\n",
        "4. Augments the cropped pieces (creates multiple versions)\n",
        "5. Saves everything back to `pile_of_augmented_lego_pieces/images` and `/labels`\n",
        "\n",
        "**Final result:** Your original folder will contain:\n",
        "- Original pile images\n",
        "- Augmented pile images (with noise, rotation, brightness variations)\n",
        "- Augmented cropped individual pieces\n",
        "\n",
        "This gives your model training data for both **pile detection** and **individual piece recognition**!"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup: Check GPU and Memory"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "gpu_check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb086c4-e8d5-4ce6-ab7e-1095561b8871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check memory\n",
        "!free -h"
      ],
      "metadata": {
        "id": "memory_check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2068a1a4-a9b4-4f1f-87db-04ec07657c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            52Gi       1.5Gi        48Gi       1.0Mi       3.4Gi        50Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "nvidia_smi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f161172-54fe-4c67-dbad-3e1eb26748ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 23 16:16:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   53C    P8             17W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "drive_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RYC8BU7P4tMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "mount_drive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4a1b73-f953-4e9d-ec65-c10527200991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Packages"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations opencv-python-headless -q"
      ],
      "metadata": {
        "id": "install_packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "import_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "import_libs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Augmentation Pipeline"
      ],
      "metadata": {
        "id": "augmentation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation pipeline for individual LEGO pieces\n",
        "# BALANCED VERSION - handles mixed quality (clean studio + noisy camera photos)\n",
        "individual_piece_augmentation = A.Compose([\n",
        "    # Rotation and flipping\n",
        "    A.Rotate(limit=180, border_mode=cv2.BORDER_REPLICATE, p=0.8),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "\n",
        "    # Lighting variations (moderate range for mixed sources)\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=(-0.1, 0.15),   # Slight darkening to moderate brightening\n",
        "        contrast_limit=0.2,               # Moderate contrast changes\n",
        "        p=0.6                             # 60% probability\n",
        "    ),\n",
        "\n",
        "    # Color variations (moderate)\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=15,\n",
        "        sat_shift_limit=20,\n",
        "        val_shift_limit=15,\n",
        "        p=0.4\n",
        "    ),\n",
        "\n",
        "    # Camera effects (MODERATE - won't over-augment noisy images)\n",
        "    A.OneOf([\n",
        "        A.MultiplicativeNoise(\n",
        "            multiplier=(0.88, 1.12),     # Moderate noise\n",
        "            per_channel=True,\n",
        "            p=1.0\n",
        "        ),\n",
        "        A.ISONoise(\n",
        "            color_shift=(0.01, 0.06),    # Moderate color shift\n",
        "            intensity=(0.15, 0.45),      # Moderate intensity\n",
        "            p=1.0\n",
        "        ),\n",
        "        A.GaussNoise(var_limit=(10.0, 40.0), p=1.0),  # Moderate Gaussian\n",
        "    ], p=0.5),                            # 50% chance - balanced approach\n",
        "\n",
        "    # Blur (light)\n",
        "    A.OneOf([\n",
        "        A.MotionBlur(blur_limit=5, p=1.0),\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
        "    ], p=0.3),                            # Only 30% - keeps sharpness\n",
        "\n",
        "    # Lighting effects (subtle)\n",
        "    A.RandomToneCurve(scale=0.06, p=0.25),\n",
        "\n",
        "    # Compression (moderate)\n",
        "    A.ImageCompression(\n",
        "        quality_range=(70, 95),           # Good quality range\n",
        "        p=0.4                             # Moderate probability\n",
        "    ),\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "print(\"‚úÖ Balanced augmentation pipeline configured!\")\n",
        "print(\"   - Works for both clean studio AND noisy camera images\")\n",
        "print(\"   - Moderate augmentations prevent over-processing\")\n",
        "print(\"   - 50% noise chance - adds variety without overdoing it\")\n",
        "print(\"   - RandomShadow REMOVED to prevent overly dark pieces\")"
      ],
      "metadata": {
        "id": "augmentation_pipeline",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deff993c-c159-42d2-f0b9-df0c4e1c6c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Balanced augmentation pipeline configured!\n",
            "   - Works for both clean studio AND noisy camera images\n",
            "   - Moderate augmentations prevent over-processing\n",
            "   - 50% noise chance - adds variety without overdoing it\n",
            "   - RandomShadow REMOVED to prevent overly dark pieces\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-502790417.py:36: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 40.0), p=1.0),  # Moderate Gaussian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Helper Functions"
      ],
      "metadata": {
        "id": "helpers_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_yolo_label(label_path):\n",
        "    \"\"\"Parse YOLO format label file with validation\"\"\"\n",
        "    bboxes = []\n",
        "    class_ids = []\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                x_center, y_center, width, height = map(float, parts[1:5])\n",
        "\n",
        "                # Clip coordinates to valid range [0, 1]\n",
        "                x_center = np.clip(x_center, 0.0, 1.0)\n",
        "                y_center = np.clip(y_center, 0.0, 1.0)\n",
        "                width = np.clip(width, 0.0, 1.0)\n",
        "                height = np.clip(height, 0.0, 1.0)\n",
        "\n",
        "                # Skip invalid bounding boxes (zero or tiny width/height)\n",
        "                if width <= 0.001 or height <= 0.001:\n",
        "                    continue\n",
        "\n",
        "                # Ensure bbox doesn't go outside image bounds\n",
        "                x_center = np.clip(x_center, width/2, 1.0 - width/2)\n",
        "                y_center = np.clip(y_center, height/2, 1.0 - height/2)\n",
        "\n",
        "                bboxes.append([x_center, y_center, width, height])\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    return bboxes, class_ids\n",
        "\n",
        "def yolo_to_pixel_coords(bbox, img_width, img_height, padding=20):\n",
        "    \"\"\"Convert YOLO bbox to pixel coordinates with padding\"\"\"\n",
        "    x_center, y_center, width, height = bbox\n",
        "\n",
        "    # Convert to pixels\n",
        "    x_center_px = x_center * img_width\n",
        "    y_center_px = y_center * img_height\n",
        "    width_px = width * img_width\n",
        "    height_px = height * img_height\n",
        "\n",
        "    # Add padding\n",
        "    x1 = max(0, int(x_center_px - width_px/2 - padding))\n",
        "    y1 = max(0, int(y_center_px - height_px/2 - padding))\n",
        "    x2 = min(img_width, int(x_center_px + width_px/2 + padding))\n",
        "    y2 = min(img_height, int(y_center_px + height_px/2 + padding))\n",
        "\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "print(\"‚úÖ Helper functions defined!\")"
      ],
      "metadata": {
        "id": "helper_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98d6ac9-fa48-46b0-eddb-3369ae2d1eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helper functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Processing Function"
      ],
      "metadata": {
        "id": "main_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_lego_dataset(base_path, num_augmentations=5, num_pile_augmentations=3, padding=20, split=''):\n",
        "    \"\"\"\n",
        "    Complete pipeline:\n",
        "    1. Augment original pile images\n",
        "    2. Crop individual pieces from original piles\n",
        "    3. Augment the cropped pieces\n",
        "    4. Save everything back to original folder\n",
        "\n",
        "    Args:\n",
        "        base_path: Path to pile_of_augmented_lego_pieces folder\n",
        "        num_augmentations: Number of augmented versions to create per cropped piece\n",
        "        num_pile_augmentations: Number of augmented versions to create per pile image\n",
        "        padding: Pixels to add around each piece when cropping\n",
        "        split: Subfolder name ('' for root, 'train' for train folder)\n",
        "    \"\"\"\n",
        "    base_path = Path(base_path)\n",
        "\n",
        "    # Define directories\n",
        "    image_dir = base_path / 'images' / split if split else base_path / 'images'\n",
        "    label_dir = base_path / 'labels' / split if split else base_path / 'labels'\n",
        "\n",
        "    # Verify directories exist\n",
        "    if not image_dir.exists():\n",
        "        print(f\"‚ùå Image directory not found: {image_dir}\")\n",
        "        return\n",
        "\n",
        "    if not label_dir.exists():\n",
        "        print(f\"‚ùå Label directory not found: {label_dir}\")\n",
        "        return\n",
        "\n",
        "    # Get all original pile images (not augmented ones we'll create)\n",
        "    # Only process original images without '_pile_aug' or '_piece' in the name\n",
        "    all_images = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
        "    image_files = [img for img in all_images if '_pile_aug' not in img.stem and '_piece' not in img.stem]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"‚ùå No original images found in {image_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"LEGO Dataset Processing Pipeline\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Source folder: {base_path}\")\n",
        "    print(f\"Original pile images: {len(image_files)}\")\n",
        "    print(f\"Augmentations per pile image: {num_pile_augmentations}\")\n",
        "    print(f\"Augmentations per cropped piece: {num_augmentations}\")\n",
        "    print(f\"Padding around pieces: {padding}px\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    total_pieces_created = 0\n",
        "    total_augmentations_created = 0\n",
        "    total_pile_augmentations_created = 0\n",
        "\n",
        "    # ============================================\n",
        "    # STEP 1: Augment Original Pile Images\n",
        "    # ============================================\n",
        "    print(\"\\nüì∏ STEP 1: Augmenting original pile images...\\n\")\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"Augmenting pile images\"):\n",
        "        # Read image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is None:\n",
        "            print(f\"‚ö†Ô∏è Could not read image: {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Read corresponding label\n",
        "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
        "        if not label_path.exists():\n",
        "            print(f\"‚ö†Ô∏è No label found for: {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        bboxes, class_ids = parse_yolo_label(label_path)\n",
        "\n",
        "        if not bboxes:\n",
        "            print(f\"‚ö†Ô∏è No bounding boxes in label: {label_path.name}\")\n",
        "            continue\n",
        "\n",
        "        # Create augmented versions of the pile image\n",
        "        for pile_aug_idx in range(num_pile_augmentations):\n",
        "            try:\n",
        "                # Apply augmentation to the full pile image\n",
        "                augmented = individual_piece_augmentation(\n",
        "                    image=image_rgb,\n",
        "                    bboxes=bboxes,\n",
        "                    class_labels=class_ids\n",
        "                )\n",
        "\n",
        "                aug_image = augmented['image']\n",
        "                aug_bboxes = augmented['bboxes']\n",
        "                aug_labels = augmented['class_labels']\n",
        "\n",
        "                # Skip if bboxes were lost during augmentation\n",
        "                if not aug_bboxes:\n",
        "                    continue\n",
        "\n",
        "                # Generate unique filename for pile augmentation\n",
        "                pile_aug_name = f\"{img_path.stem}_pile_aug{pile_aug_idx:02d}\"\n",
        "\n",
        "                # Save augmented pile image\n",
        "                output_img_path = image_dir / f\"{pile_aug_name}{img_path.suffix}\"\n",
        "                cv2.imwrite(str(output_img_path), cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                # Save augmented pile label\n",
        "                output_label_path = label_dir / f\"{pile_aug_name}.txt\"\n",
        "                with open(output_label_path, 'w') as f:\n",
        "                    for bbox_aug, label_aug in zip(aug_bboxes, aug_labels):\n",
        "                        f.write(f\"{label_aug} {bbox_aug[0]} {bbox_aug[1]} {bbox_aug[2]} {bbox_aug[3]}\\n\")\n",
        "\n",
        "                total_pile_augmentations_created += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Pile augmentation failed for {img_path.name}_aug{pile_aug_idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"\\n‚úÖ Created {total_pile_augmentations_created} augmented pile images\\n\")\n",
        "\n",
        "    # ============================================\n",
        "    # STEP 2: Crop and Augment Individual Pieces\n",
        "    # ============================================\n",
        "    print(\"\\n‚úÇÔ∏è STEP 2: Cropping and augmenting individual pieces...\\n\")\n",
        "\n",
        "    # Process each original pile image for cropping\n",
        "    for img_idx, img_path in enumerate(tqdm(image_files, desc=\"Processing pile images\")):\n",
        "        # Read image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is None:\n",
        "            print(f\"‚ö†Ô∏è Could not read image: {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        img_height, img_width = image.shape[:2]\n",
        "\n",
        "        # Read corresponding label\n",
        "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
        "        if not label_path.exists():\n",
        "            print(f\"‚ö†Ô∏è No label found for: {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        bboxes, class_ids = parse_yolo_label(label_path)\n",
        "\n",
        "        if not bboxes:\n",
        "            print(f\"‚ö†Ô∏è No bounding boxes in label: {label_path.name}\")\n",
        "            continue\n",
        "\n",
        "        # Crop each piece from this image\n",
        "        for piece_idx, (bbox, class_id) in enumerate(zip(bboxes, class_ids)):\n",
        "            x1, y1, x2, y2 = yolo_to_pixel_coords(bbox, img_width, img_height, padding)\n",
        "\n",
        "            # Crop the piece\n",
        "            cropped = image[y1:y2, x1:x2]\n",
        "\n",
        "            if cropped.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate new bbox for cropped piece (centered)\n",
        "            crop_width = x2 - x1\n",
        "            crop_height = y2 - y1\n",
        "            orig_width_px = bbox[2] * img_width\n",
        "            orig_height_px = bbox[3] * img_height\n",
        "\n",
        "            new_x_center = 0.5\n",
        "            new_y_center = 0.5\n",
        "            new_width = orig_width_px / crop_width\n",
        "            new_height = orig_height_px / crop_height\n",
        "\n",
        "            # Convert cropped image to RGB for augmentation\n",
        "            cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Create augmented versions of this cropped piece\n",
        "            for aug_idx in range(num_augmentations):\n",
        "                try:\n",
        "                    # Apply augmentation\n",
        "                    augmented = individual_piece_augmentation(\n",
        "                        image=cropped_rgb,\n",
        "                        bboxes=[[new_x_center, new_y_center, new_width, new_height]],\n",
        "                        class_labels=[class_id]\n",
        "                    )\n",
        "\n",
        "                    aug_image = augmented['image']\n",
        "                    aug_bboxes = augmented['bboxes']\n",
        "                    aug_labels = augmented['class_labels']\n",
        "\n",
        "                    # Skip if bbox was lost during augmentation\n",
        "                    if not aug_bboxes:\n",
        "                        continue\n",
        "\n",
        "                    # Generate unique filename\n",
        "                    piece_name = f\"{img_path.stem}_piece{piece_idx:04d}_aug{aug_idx:02d}\"\n",
        "\n",
        "                    # Save augmented image\n",
        "                    output_img_path = image_dir / f\"{piece_name}{img_path.suffix}\"\n",
        "                    cv2.imwrite(str(output_img_path), cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    # Save augmented label\n",
        "                    output_label_path = label_dir / f\"{piece_name}.txt\"\n",
        "                    with open(output_label_path, 'w') as f:\n",
        "                        for bbox_aug, label_aug in zip(aug_bboxes, aug_labels):\n",
        "                            f.write(f\"{label_aug} {bbox_aug[0]} {bbox_aug[1]} {bbox_aug[2]} {bbox_aug[3]}\\n\")\n",
        "\n",
        "                    total_augmentations_created += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Augmentation failed for {img_path.stem}_piece{piece_idx}_aug{aug_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            total_pieces_created += 1\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"‚úÖ Processing Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Original pile images: {len(image_files)}\")\n",
        "    print(f\"Augmented pile images: {total_pile_augmentations_created}\")\n",
        "    print(f\"Cropped pieces: {total_pieces_created}\")\n",
        "    print(f\"Augmented cropped pieces: {total_augmentations_created}\")\n",
        "    print(f\"\\nüìä Total images in dataset now:\")\n",
        "    print(f\"   Original piles: {len(image_files)}\")\n",
        "    print(f\"   + Augmented piles: {total_pile_augmentations_created}\")\n",
        "    print(f\"   + Augmented cropped pieces: {total_augmentations_created}\")\n",
        "    print(f\"   = TOTAL: {len(image_files) + total_pile_augmentations_created + total_augmentations_created}\")\n",
        "    print(f\"\\nüìÅ All saved to: {base_path}\")\n",
        "    print(f\"   Images: {image_dir}\")\n",
        "    print(f\"   Labels: {label_dir}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(\"‚úÖ Main processing function defined!\")"
      ],
      "metadata": {
        "id": "main_function",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c0db2b-0a54-4ff0-b154-e95907aa9022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Main processing function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Complete Pipeline\n",
        "\n",
        "This will:\n",
        "1. **Augment the original pile images** (creates 3 versions with noise, rotation, brightness)\n",
        "2. **Crop individual LEGO pieces** from the original pile images\n",
        "3. **Augment the cropped pieces** (creates 5 versions per piece)\n",
        "4. Save everything back to the same folder\n",
        "\n",
        "**Your final dataset will contain:**\n",
        "- Original pile images (for detecting pieces in cluttered scenes)\n",
        "- Augmented pile images (more training variety for pile detection)\n",
        "- Augmented individual pieces (for piece recognition)\n",
        "\n",
        "**Note:** This will take some time depending on how many pieces are in your images!"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your base path\n",
        "base_path = '/content/drive/MyDrive/lego-training/pile_of_augmented_lego_pieces'\n",
        "\n",
        "# Run the complete pipeline\n",
        "process_lego_dataset(\n",
        "    base_path=base_path,\n",
        "    num_augmentations=5,          # Create 5 augmented versions per cropped piece\n",
        "    num_pile_augmentations=3,     # Create 3 augmented versions per pile image\n",
        "    padding=20,                   # 20 pixels of padding around each piece\n",
        "    split=''                      # Use '' if no train subfolder, 'train' if you have one\n",
        ")"
      ],
      "metadata": {
        "id": "run_pipeline",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "084d00af-adf0-4dae-f6bb-00f9ab7f30ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LEGO Dataset Processing Pipeline\n",
            "============================================================\n",
            "Source folder: /Volumes/lego-Images/pile_of_augmented_lego_pieces\n",
            "Original pile images: 2000\n",
            "Augmentations per pile image: 3\n",
            "Augmentations per cropped piece: 5\n",
            "Padding around pieces: 20px\n",
            "============================================================\n",
            "\n",
            "\n",
            "üì∏ STEP 1: Augmenting original pile images...\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  30%|‚ñà‚ñà‚ñâ       | 597/2000 [31:21<1:12:08,  3.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 550.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 867/2000 [43:32<32:41,  1.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 1001.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 999/2000 [49:38<1:01:36,  3.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: ._1646.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1732/2000 [1:46:59<19:12,  4.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 1646.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1864/2000 [1:59:01<09:41,  4.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 1094.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1931/2000 [2:05:11<06:15,  5.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 1334.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting pile images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [2:11:14<00:00,  3.94s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Created 5982 augmented pile images\n",
            "\n",
            "\n",
            "‚úÇÔ∏è STEP 2: Cropping and augmenting individual pieces...\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing pile images:  30%|‚ñà‚ñà‚ñâ       | 598/2000 [5:26:33<10:08:32, 26.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 550.png\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing pile images:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 867/2000 [8:16:01<9:10:12, 29.14s/it] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not read image: 1001.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pile images:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1000/2000 [9:43:53<8:03:11, 28.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Could not read image: ._1646.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pile images:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1517/2000 [15:55:48<5:04:19, 37.80s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1462824528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the complete pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m process_lego_dataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_augmentations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Create 5 augmented versions per cropped piece\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-706314236.py\u001b[0m in \u001b[0;36mprocess_lego_dataset\u001b[0;34m(base_path, num_augmentations, num_pile_augmentations, padding, split)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0;31m# Save augmented image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0moutput_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{piece_name}{img_path.suffix}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Save augmented label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Results"
      ],
      "metadata": {
        "id": "verify_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the output\n",
        "base_path = Path('/content/drive/MyDrive/lego-training/pile_of_augmented_lego_pieces')\n",
        "image_dir = base_path / 'images'\n",
        "label_dir = base_path / 'labels'\n",
        "\n",
        "print(f\"\\nüìä Dataset Summary\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "if image_dir.exists():\n",
        "    all_images = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
        "    original_images = [img for img in all_images if '_piece' not in img.stem]\n",
        "    augmented_images = [img for img in all_images if '_piece' in img.stem]\n",
        "\n",
        "    print(f\"Total images: {len(all_images)}\")\n",
        "    print(f\"  - Original pile images: {len(original_images)}\")\n",
        "    print(f\"  - Augmented cropped pieces: {len(augmented_images)}\")\n",
        "else:\n",
        "    print(\"‚ùå Image directory not found\")\n",
        "\n",
        "if label_dir.exists():\n",
        "    all_labels = list(label_dir.glob('*.txt'))\n",
        "    print(f\"\\nTotal labels: {len(all_labels)}\")\n",
        "else:\n",
        "    print(\"‚ùå Label directory not found\")\n",
        "\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "id": "verify_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Proper split"
      ],
      "metadata": {
        "id": "o04lG_iZYRZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "print(\"üîÑ SPLIT USING REAL DRIVE PATH (NO SYMLINK)\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# USE REAL DRIVE PATH ONLY!\n",
        "dataset_path = Path('/content/drive/MyDrive/lego-training/pile_of_augmented_lego_pieces')\n",
        "images_dir = dataset_path / 'images'\n",
        "labels_dir = dataset_path / 'labels'\n",
        "\n",
        "# Step 1: Clean up any existing train/val folders\n",
        "print(\"üßπ Cleaning up old train/val folders...\")\n",
        "for folder in ['train', 'val']:\n",
        "    for parent in [images_dir, labels_dir]:\n",
        "        folder_path = parent / folder\n",
        "        if folder_path.exists():\n",
        "            try:\n",
        "                shutil.rmtree(str(folder_path))\n",
        "                print(f\"  ‚úÖ Deleted {folder_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è  {folder_path}: {e}\")\n",
        "\n",
        "# Step 2: Verify all files are in root\n",
        "print(\"\\nüìä Checking root files...\")\n",
        "image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpeg'))\n",
        "label_files = list(labels_dir.glob('*.txt'))\n",
        "\n",
        "print(f\"  Images: {len(image_files):,}\")\n",
        "print(f\"  Labels: {len(label_files):,}\")\n",
        "\n",
        "if len(image_files) < 230000:\n",
        "    print(\"\\n‚ùå Not enough files! Aborting.\")\n",
        "else:\n",
        "    # Step 3: Split\n",
        "    print(\"\\nüì¶ Splitting...\")\n",
        "    random.seed(42)\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    split_idx = int(len(image_files) * 0.8)\n",
        "    train_imgs = image_files[:split_idx]\n",
        "    val_imgs = image_files[split_idx:]\n",
        "\n",
        "    print(f\"  Train: {len(train_imgs):,}\")\n",
        "    print(f\"  Val: {len(val_imgs):,}\")\n",
        "\n",
        "    # Create fresh directories\n",
        "    (images_dir / 'train').mkdir()\n",
        "    (images_dir / 'val').mkdir()\n",
        "    (labels_dir / 'train').mkdir()\n",
        "    (labels_dir / 'val').mkdir()\n",
        "\n",
        "    # Move training\n",
        "    print(f\"\\nüöö Moving training...\")\n",
        "    for i, img in enumerate(train_imgs):\n",
        "        if i % 10000 == 0:\n",
        "            print(f\"  {i:,}\")\n",
        "        shutil.move(str(img), str(images_dir / 'train' / img.name))\n",
        "        lbl = labels_dir / f\"{img.stem}.txt\"\n",
        "        if lbl.exists():\n",
        "            shutil.move(str(lbl), str(labels_dir / 'train' / lbl.name))\n",
        "\n",
        "    # Move validation\n",
        "    print(f\"\\nüöö Moving validation...\")\n",
        "    for i, img in enumerate(val_imgs):\n",
        "        if i % 10000 == 0:\n",
        "            print(f\"  {i:,}\")\n",
        "        shutil.move(str(img), str(images_dir / 'val' / img.name))\n",
        "        lbl = labels_dir / f\"{img.stem}.txt\"\n",
        "        if lbl.exists():\n",
        "            shutil.move(str(lbl), str(labels_dir / 'val' / lbl.name))\n",
        "\n",
        "    # Verify\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    t_i = len(list((images_dir / 'train').glob('*')))\n",
        "    v_i = len(list((images_dir / 'val').glob('*')))\n",
        "    t_l = len(list((labels_dir / 'train').glob('*.txt')))\n",
        "    v_l = len(list((labels_dir / 'val').glob('*.txt')))\n",
        "\n",
        "    print(f\"‚úÖ train: {t_i:,} imgs / {t_l:,} lbls\")\n",
        "    print(f\"‚úÖ val:   {v_i:,} imgs / {v_l:,} lbls\")\n",
        "\n",
        "    if v_i > 40000 and v_l > 40000:\n",
        "        print(\"\\n‚úÖ‚úÖ‚úÖ SUCCESS! ‚úÖ‚úÖ‚úÖ\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå PROBLEM!\")"
      ],
      "metadata": {
        "id": "zwfYb07SYUXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload to GCS"
      ],
      "metadata": {
        "id": "vDqLD71xd0eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set project\n",
        "!gcloud config set project lego-training\n",
        "\n",
        "# Upload from Drive to GCS (one-time, 20-30 min)\n",
        "!gsutil -m cp -r /content/drive/MyDrive/lego-training/pile_of_augmented_lego_pieces gs://lego-dataset-di/\n",
        "\n",
        "print(\"‚úÖ Uploaded to GCS!\")"
      ],
      "metadata": {
        "id": "awOBZDCYdx2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading dataset from GCS to Colab local storage"
      ],
      "metadata": {
        "id": "gE2RB-tLpmrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"‚¨áÔ∏è Downloading dataset from GCS to Colab local storage\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Create directory structure FIRST\n",
        "print(\"üìÅ Creating directory structure...\")\n",
        "!mkdir -p /content/dataset/pile_of_augmented_lego_pieces/images\n",
        "!mkdir -p /content/dataset/pile_of_augmented_lego_pieces/labels\n",
        "\n",
        "# Download with trailing slashes (tells gsutil these are directories)\n",
        "print(\"\\nüì¶ Downloading 232K files from GCS...\")\n",
        "print(\"   This may take 3-5 minutes...\\n\")\n",
        "\n",
        "!gsutil -m rsync -r gs://lego-dataset-di/pile_of_augmented_lego_pieces/ /content/dataset/pile_of_augmented_lego_pieces/\n",
        "\n",
        "print(\"\\n‚úÖ Download complete!\")\n",
        "\n",
        "# Verification\n",
        "import os\n",
        "img_count = len([f for f in os.listdir('/content/dataset/pile_of_augmented_lego_pieces/images') if f.endswith('.png')])\n",
        "lbl_count = len([f for f in os.listdir('/content/dataset/pile_of_augmented_lego_pieces/labels') if f.endswith('.txt')])\n",
        "print(f\"\\nüìä Downloaded: {img_count:,} images, {lbl_count:,} labels\")\n"
      ],
      "metadata": {
        "id": "x-yUlrDcpfu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cell 1: Configure Paths"
      ],
      "metadata": {
        "id": "ze_8FTKmpLtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update these paths to match your dataset location\n",
        "SOURCE_IMAGES = '/content/dataset/pile_of_augmented_lego_pieces/images'\n",
        "SOURCE_LABELS = '/content/dataset/pile_of_augmented_lego_pieces/labels'\n",
        "OUTPUT_DIR = '/content/dataset/lego_split'\n",
        "\n",
        "# Split ratio (0.8 = 80% train, 20% validation)\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "print(f\"‚úÖ Source images: {SOURCE_IMAGES}\")\n",
        "print(f\"‚úÖ Source labels: {SOURCE_LABELS}\")\n",
        "print(f\"‚úÖ Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"‚úÖ Train/Val split: {TRAIN_RATIO*100:.0f}% / {(1-TRAIN_RATIO)*100:.0f}%\")"
      ],
      "metadata": {
        "id": "Iga0QJu0pPUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cell 2: Dataset Splitter Function"
      ],
      "metadata": {
        "id": "3qG4Ip7wp5xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "def split_yolo_dataset_stratified(source_images_dir, source_labels_dir, output_dir, train_ratio=0.8, seed=42):\n",
        "    \"\"\"\n",
        "    Split YOLO dataset into train/val sets with STRATIFIED class distribution\n",
        "    Ensures ALL classes appear in both train and validation sets\n",
        "    NO DATA LEAKAGE - each image appears in only one set\n",
        "    \"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Convert to Path objects\n",
        "    source_images = Path(source_images_dir)\n",
        "    source_labels = Path(source_labels_dir)\n",
        "    output = Path(output_dir)\n",
        "\n",
        "    # Create output directory structure\n",
        "    train_images = output / 'train' / 'images'\n",
        "    train_labels = output / 'train' / 'labels'\n",
        "    val_images = output / 'val' / 'images'\n",
        "    val_labels = output / 'val' / 'labels'\n",
        "\n",
        "    for folder in [train_images, train_labels, val_images, val_labels]:\n",
        "        folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéØ YOLO Dataset Splitter for LEGO Pieces (STRATIFIED)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get all image files\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "    all_images = [f for f in source_images.iterdir()\n",
        "                  if f.suffix.lower() in image_extensions]\n",
        "\n",
        "    print(f\"\\nüìÅ Source: {source_images}\")\n",
        "    print(f\"üìä Total images found: {len(all_images)}\")\n",
        "\n",
        "    # Map each image to its classes\n",
        "    image_to_classes = {}\n",
        "    class_to_images = defaultdict(set)\n",
        "    valid_pairs = []\n",
        "    missing_labels = []\n",
        "\n",
        "    for img_path in all_images:\n",
        "        label_path = source_labels / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        if label_path.exists():\n",
        "            valid_pairs.append((img_path, label_path))\n",
        "            image_classes = set()\n",
        "\n",
        "            # Read label file to track class distribution\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        class_id = int(parts[0])\n",
        "                        image_classes.add(class_id)\n",
        "                        class_to_images[class_id].add(img_path.stem)\n",
        "\n",
        "            image_to_classes[img_path.stem] = image_classes\n",
        "        else:\n",
        "            missing_labels.append(img_path.name)\n",
        "\n",
        "    print(f\"‚úÖ Valid image-label pairs: {len(valid_pairs)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(f\"‚ö†Ô∏è  Missing labels for {len(missing_labels)} images\")\n",
        "\n",
        "    # LEGO class names\n",
        "    class_names = {\n",
        "        0: \"Plates Special\", 1: \"Bars, Ladders and Fences\", 2: \"Bricks Special\",\n",
        "        3: \"Plates\", 4: \"Technic Pins\", 5: \"Bricks Curved\", 6: \"Tiles\",\n",
        "        7: \"Tiles Round and Curved\", 8: \"Technic Connectors\", 9: \"Technic Special\",\n",
        "        10: \"Projectiles / Launchers\", 11: \"Tiles Special\", 12: \"Bricks Sloped\",\n",
        "        13: \"Bricks\", 14: \"Hinges, Arms and Turntables\", 15: \"Plates Angled\",\n",
        "        16: \"Plants and Animals\", 17: \"Plates Round Curved and Dishes\",\n",
        "        18: \"Bricks Round and Cones\", 19: \"Technic Bricks\", 20: \"Technic Axles\",\n",
        "        21: \"Technic Beams\", 22: \"Technic Bushes\", 23: \"Minifig Accessories\",\n",
        "        24: \"Panels\", 25: \"Windows and Doors\", 26: \"Bricks Wedged\",\n",
        "        27: \"Duplo, Quatro and Primo\", 28: \"Supports, Girders and Cranes\",\n",
        "        29: \"Technic Beams Special\", 30: \"Transportation - Land\", 31: \"Technic Gears\",\n",
        "        32: \"Technic Panels\", 33: \"Technic Steering, Suspension and Engine\",\n",
        "        34: \"Wheels and Tyres\", 35: \"Large Buildable Figures\", 36: \"Pneumatics\",\n",
        "        37: \"String, Bands and Reels\", 38: \"Transportation - Sea and Air\",\n",
        "        39: \"Electronics\", 40: \"Energy Effects\", 41: \"Rock\", 42: \"Minifig Headwear\",\n",
        "        43: \"Windscreens and Fuselage\", 44: \"Containers\", 45: \"Tools\",\n",
        "        46: \"Minifigs\", 47: \"Minifig Lower Body\", 48: \"Baseplates\",\n",
        "        49: \"Minifig Upper Body\", 50: \"Flags, Signs, Plastics and Cloth\",\n",
        "        51: \"Tubes and Hoses\"\n",
        "    }\n",
        "\n",
        "    # Display class distribution\n",
        "    print(f\"\\nüìä Class Distribution:\")\n",
        "    sorted_classes = sorted(class_to_images.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "    for class_id, images in sorted_classes:\n",
        "        count = len(images)\n",
        "        name = class_names.get(class_id, \"Unknown\")\n",
        "        print(f\"   Class {class_id:2d}: {count:5d} images - {name}\")\n",
        "\n",
        "    # STRATIFIED SPLIT: Assign each image to train or val, ensuring class balance\n",
        "    # FIXED: Prevents data leakage by assigning each image only once\n",
        "    train_set = set()\n",
        "    val_set = set()\n",
        "\n",
        "    print(f\"\\nüîÑ Performing stratified split (preventing data leakage)...\")\n",
        "\n",
        "    # Sort classes by size (smallest first) to handle rare classes carefully\n",
        "    sorted_class_list = sorted(class_to_images.items(), key=lambda x: len(x[1]))\n",
        "\n",
        "    for class_id, image_stems in sorted_class_list:\n",
        "        images_list = list(image_stems)\n",
        "        random.shuffle(images_list)\n",
        "\n",
        "        # Separate unassigned images from already assigned ones\n",
        "        unassigned = [img for img in images_list if img not in train_set and img not in val_set]\n",
        "\n",
        "        if not unassigned:\n",
        "            continue  # All images of this class already assigned\n",
        "\n",
        "        # Calculate target split for unassigned images\n",
        "        target_train = max(1, int(len(unassigned) * train_ratio))\n",
        "        target_val = len(unassigned) - target_train\n",
        "\n",
        "        # Ensure at least 1 image in validation if possible\n",
        "        if target_val == 0 and len(unassigned) > 1:\n",
        "            target_train = len(unassigned) - 1\n",
        "            target_val = 1\n",
        "\n",
        "        # Assign unassigned images\n",
        "        train_set.update(unassigned[:target_train])\n",
        "        val_set.update(unassigned[target_train:])\n",
        "\n",
        "    # Verify no overlap\n",
        "    overlap = train_set & val_set\n",
        "    if overlap:\n",
        "        print(f\"‚ùå ERROR: {len(overlap)} images in both sets! (This shouldn't happen)\")\n",
        "        print(f\"   Example: {list(overlap)[:5]}\")\n",
        "    else:\n",
        "        print(f\"‚úÖ No data leakage: {len(train_set)} train, {len(val_set)} val (no overlap)\")\n",
        "\n",
        "    # Convert back to paths\n",
        "    train_pairs = [(img_path, source_labels / f\"{img_path.stem}.txt\")\n",
        "                   for img_path, _ in valid_pairs if img_path.stem in train_set]\n",
        "    val_pairs = [(img_path, source_labels / f\"{img_path.stem}.txt\")\n",
        "                 for img_path, _ in valid_pairs if img_path.stem in val_set]\n",
        "\n",
        "    print(f\"\\nüìä Split Summary:\")\n",
        "    print(f\"   Training set: {len(train_pairs)} images ({len(train_pairs)/len(valid_pairs)*100:.1f}%)\")\n",
        "    print(f\"   Validation set: {len(val_pairs)} images ({len(val_pairs)/len(valid_pairs)*100:.1f}%)\")\n",
        "\n",
        "    # Copy files to train folder\n",
        "    print(f\"\\nüìã Copying training files...\")\n",
        "    for i, (img_path, label_path) in enumerate(train_pairs):\n",
        "        shutil.copy2(img_path, train_images / img_path.name)\n",
        "        shutil.copy2(label_path, train_labels / label_path.name)\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(f\"   Copied {i + 1}/{len(train_pairs)} train files...\")\n",
        "\n",
        "    # Copy files to val folder\n",
        "    print(f\"\\nüìã Copying validation files...\")\n",
        "    for i, (img_path, label_path) in enumerate(val_pairs):\n",
        "        shutil.copy2(img_path, val_images / img_path.name)\n",
        "        shutil.copy2(label_path, val_labels / label_path.name)\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(f\"   Copied {i + 1}/{len(val_pairs)} val files...\")\n",
        "\n",
        "    # Verify class distribution in splits\n",
        "    print(f\"\\n‚úÖ Verifying stratified split...\")\n",
        "    train_classes = set()\n",
        "    val_classes = set()\n",
        "    train_class_counts = defaultdict(int)\n",
        "    val_class_counts = defaultdict(int)\n",
        "\n",
        "    for _, label_path in train_pairs:\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    cls = int(parts[0])\n",
        "                    train_classes.add(cls)\n",
        "                    train_class_counts[cls] += 1\n",
        "\n",
        "    for _, label_path in val_pairs:\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    cls = int(parts[0])\n",
        "                    val_classes.add(cls)\n",
        "                    val_class_counts[cls] += 1\n",
        "\n",
        "    print(f\"   Training set has {len(train_classes)} classes\")\n",
        "    print(f\"   Validation set has {len(val_classes)} classes\")\n",
        "\n",
        "    missing_in_val = train_classes - val_classes\n",
        "    missing_in_train = val_classes - train_classes\n",
        "\n",
        "    if missing_in_val:\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNING: {len(missing_in_val)} classes missing from validation:\")\n",
        "        for cls_id in sorted(missing_in_val):\n",
        "            print(f\"   - Class {cls_id}: {class_names.get(cls_id, 'Unknown')} ({train_class_counts[cls_id]} in train)\")\n",
        "\n",
        "    if missing_in_train:\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNING: {len(missing_in_train)} classes missing from training:\")\n",
        "        for cls_id in sorted(missing_in_train):\n",
        "            print(f\"   - Class {cls_id}: {class_names.get(cls_id, 'Unknown')} ({val_class_counts[cls_id]} in val)\")\n",
        "\n",
        "    if not missing_in_val and not missing_in_train:\n",
        "        print(f\"\\n‚úÖ Perfect! All {len(class_to_images)} classes present in BOTH train and validation sets!\")\n",
        "\n",
        "    # Create updated data.yaml\n",
        "    yaml_content = f\"\"\"# LEGO Pieces Dataset - Stratified Split\n",
        "path: {output.absolute()}\n",
        "\n",
        "train: train/images\n",
        "val: val/images\n",
        "\n",
        "nc: 52\n",
        "names:\n",
        "\"\"\"\n",
        "\n",
        "    for i in range(52):\n",
        "        yaml_content += f\"  {i}: {class_names.get(i, 'Unknown')}\\n\"\n",
        "\n",
        "    yaml_path = output / 'data.yaml'\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(f\"‚úÖ Stratified dataset split complete!\")\n",
        "    print(f\"=\" * 80)\n",
        "    print(f\"\\nüìÅ Output structure:\")\n",
        "    print(f\"   {output}/\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ train/\")\n",
        "    print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ images/ ({len(train_pairs)} files)\")\n",
        "    print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ labels/ ({len(train_pairs)} files)\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ val/\")\n",
        "    print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ images/ ({len(val_pairs)} files)\")\n",
        "    print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ labels/ ({len(val_pairs)} files)\")\n",
        "    print(f\"   ‚îî‚îÄ‚îÄ data.yaml\")\n",
        "\n",
        "    print(f\"\\nüéØ Ready for training!\")\n",
        "\n",
        "    return str(yaml_path)"
      ],
      "metadata": {
        "id": "8VUG8E3lpztq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3: Run the Split"
      ],
      "metadata": {
        "id": "Pv27ZBpPqCD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the dataset split\n",
        "new_yaml_path = split_yolo_dataset_stratified(\n",
        "    source_images_dir=SOURCE_IMAGES,\n",
        "    source_labels_dir=SOURCE_LABELS,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    train_ratio=TRAIN_RATIO,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"\\n‚ú® Your new data.yaml path: {new_yaml_path}\")"
      ],
      "metadata": {
        "id": "9m5wG-GaqEJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 4: Verify the Split"
      ],
      "metadata": {
        "id": "fki1WY2TqMJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def verify_stratified_split(output_dir):\n",
        "    \"\"\"\n",
        "    Comprehensive verification to ensure val/cls_loss = inf won't happen\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üîç COMPREHENSIVE SPLIT VERIFICATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # 1. Count files\n",
        "    train_img_dir = os.path.join(output_dir, 'train', 'images')\n",
        "    train_lbl_dir = os.path.join(output_dir, 'train', 'labels')\n",
        "    val_img_dir = os.path.join(output_dir, 'val', 'images')\n",
        "    val_lbl_dir = os.path.join(output_dir, 'val', 'labels')\n",
        "\n",
        "    train_img_count = len([f for f in os.listdir(train_img_dir) if not f.startswith('.')])\n",
        "    train_lbl_count = len([f for f in os.listdir(train_lbl_dir) if f.endswith('.txt')])\n",
        "    val_img_count = len([f for f in os.listdir(val_img_dir) if not f.startswith('.')])\n",
        "    val_lbl_count = len([f for f in os.listdir(val_lbl_dir) if f.endswith('.txt')])\n",
        "\n",
        "    print(\"\\nüìä File Count Verification:\")\n",
        "    print(f\"  Training Set:\")\n",
        "    print(f\"    Images: {train_img_count}\")\n",
        "    print(f\"    Labels: {train_lbl_count}\")\n",
        "    print(f\"    Match: {'‚úÖ' if train_img_count == train_lbl_count else '‚ùå MISMATCH!'}\")\n",
        "\n",
        "    print(f\"\\n  Validation Set:\")\n",
        "    print(f\"    Images: {val_img_count}\")\n",
        "    print(f\"    Labels: {val_lbl_count}\")\n",
        "    print(f\"    Match: {'‚úÖ' if val_img_count == val_lbl_count else '‚ùå MISMATCH!'}\")\n",
        "\n",
        "    total_images = train_img_count + val_img_count\n",
        "    print(f\"\\n  Total: {total_images} images\")\n",
        "    print(f\"  Split: {train_img_count/total_images*100:.1f}% train / {val_img_count/total_images*100:.1f}% val\")\n",
        "\n",
        "    # 2. CRITICAL: Verify class distribution\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéØ CRITICAL: Class Distribution Analysis (prevents val/cls_loss = inf)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    train_class_counts = Counter()\n",
        "    val_class_counts = Counter()\n",
        "\n",
        "    # Count classes in training\n",
        "    for label_file in os.listdir(train_lbl_dir):\n",
        "        if label_file.endswith('.txt'):\n",
        "            with open(os.path.join(train_lbl_dir, label_file), 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        train_class_counts[int(parts[0])] += 1\n",
        "\n",
        "    # Count classes in validation\n",
        "    for label_file in os.listdir(val_lbl_dir):\n",
        "        if label_file.endswith('.txt'):\n",
        "            with open(os.path.join(val_lbl_dir, label_file), 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        val_class_counts[int(parts[0])] += 1\n",
        "\n",
        "    all_classes = sorted(set(train_class_counts.keys()) | set(val_class_counts.keys()))\n",
        "\n",
        "    print(f\"\\nüìà Class Distribution Summary:\")\n",
        "    print(f\"  Classes in training: {len(train_class_counts)}\")\n",
        "    print(f\"  Classes in validation: {len(val_class_counts)}\")\n",
        "    print(f\"  Total unique classes: {len(all_classes)}\")\n",
        "\n",
        "    # CRITICAL CHECK: Classes missing from validation\n",
        "    missing_from_val = set(train_class_counts.keys()) - set(val_class_counts.keys())\n",
        "    missing_from_train = set(val_class_counts.keys()) - set(train_class_counts.keys())\n",
        "\n",
        "    if missing_from_val:\n",
        "        print(f\"\\n‚ùå CRITICAL ERROR: {len(missing_from_val)} classes MISSING from validation!\")\n",
        "        print(f\"   This WILL cause val/cls_loss = inf!\")\n",
        "        print(f\"   Missing classes: {sorted(missing_from_val)}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ EXCELLENT: All {len(train_class_counts)} classes present in BOTH sets!\")\n",
        "        print(f\"   val/cls_loss = inf will NOT occur! ‚úÖ\")\n",
        "\n",
        "    if missing_from_train:\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNING: {len(missing_from_train)} classes only in validation: {sorted(missing_from_train)}\")\n",
        "\n",
        "    # 3. Detailed class breakdown\n",
        "    print(f\"\\nüìã Detailed Class Distribution (All {len(all_classes)} classes):\")\n",
        "    print(f\"{'Class':>6} {'Train':>8} {'Val':>8} {'Total':>8} {'Val%':>6} {'Status':>10}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    class_names = {\n",
        "        0: \"Plates Special\", 1: \"Bars, Ladders and Fences\", 2: \"Bricks Special\",\n",
        "        3: \"Plates\", 4: \"Technic Pins\", 5: \"Bricks Curved\", 6: \"Tiles\",\n",
        "        7: \"Tiles Round and Curved\", 8: \"Technic Connectors\", 9: \"Technic Special\",\n",
        "        10: \"Projectiles / Launchers\", 11: \"Tiles Special\", 12: \"Bricks Sloped\",\n",
        "        13: \"Bricks\", 14: \"Hinges, Arms and Turntables\", 15: \"Plates Angled\",\n",
        "        16: \"Plants and Animals\", 17: \"Plates Round Curved and Dishes\",\n",
        "        18: \"Bricks Round and Cones\", 19: \"Technic Bricks\", 20: \"Technic Axles\",\n",
        "        21: \"Technic Beams\", 22: \"Technic Bushes\", 23: \"Minifig Accessories\",\n",
        "        24: \"Panels\", 25: \"Windows and Doors\", 26: \"Bricks Wedged\",\n",
        "        27: \"Duplo, Quatro and Primo\", 28: \"Supports, Girders and Cranes\",\n",
        "        29: \"Technic Beams Special\", 30: \"Transportation - Land\", 31: \"Technic Gears\",\n",
        "        32: \"Technic Panels\", 33: \"Technic Steering, Suspension and Engine\",\n",
        "        34: \"Wheels and Tyres\", 35: \"Large Buildable Figures\", 36: \"Pneumatics\",\n",
        "        37: \"String, Bands and Reels\", 38: \"Transportation - Sea and Air\",\n",
        "        39: \"Electronics\", 40: \"Energy Effects\", 41: \"Rock\", 42: \"Minifig Headwear\",\n",
        "        43: \"Windscreens and Fuselage\", 44: \"Containers\", 45: \"Tools\",\n",
        "        46: \"Minifigs\", 47: \"Minifig Lower Body\", 48: \"Baseplates\",\n",
        "        49: \"Minifig Upper Body\", 50: \"Flags, Signs, Plastics and Cloth\",\n",
        "        51: \"Tubes and Hoses\"\n",
        "    }\n",
        "\n",
        "    for cls in all_classes:\n",
        "        train_cnt = train_class_counts.get(cls, 0)\n",
        "        val_cnt = val_class_counts.get(cls, 0)\n",
        "        total = train_cnt + val_cnt\n",
        "        val_pct = (val_cnt / total * 100) if total > 0 else 0\n",
        "\n",
        "        if val_cnt == 0:\n",
        "            status = \"‚ùå NO VAL\"\n",
        "        elif val_cnt < 5:\n",
        "            status = \"‚ö†Ô∏è FEW VAL\"\n",
        "        else:\n",
        "            status = \"‚úÖ OK\"\n",
        "\n",
        "        print(f\"{cls:>6} {train_cnt:>8} {val_cnt:>8} {total:>8} {val_pct:>5.1f}% {status:>10}\")\n",
        "\n",
        "    # 4. Show data.yaml\n",
        "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
        "    print(f\"\\nüìÑ data.yaml preview:\")\n",
        "    print(\"=\" * 60)\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for i, line in enumerate(lines):\n",
        "            if i < 10 or i >= len(lines) - 5:\n",
        "                print(line.rstrip())\n",
        "            elif i == 10:\n",
        "                print(\"  ... (classes 10-49 omitted) ...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 5. Final verdict\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    if missing_from_val:\n",
        "        print(\"‚ùå VERIFICATION FAILED: Some classes missing from validation\")\n",
        "        print(\"   val/cls_loss = inf WILL occur with this split!\")\n",
        "        print(\"   DO NOT use this split for training!\")\n",
        "    else:\n",
        "        print(\"‚úÖ VERIFICATION PASSED: All classes present in both train and val\")\n",
        "        print(\"   val/cls_loss = inf will NOT occur! Safe to train! üéâ\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return len(missing_from_val) == 0\n",
        "\n",
        "\n",
        "# Usage:\n",
        "verify_stratified_split('/content/dataset/lego_split')"
      ],
      "metadata": {
        "id": "rw7oeb0aqPBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1: Authenticate with Google Cloud"
      ],
      "metadata": {
        "id": "8fZRoLTTquaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "print(\"‚úÖ Authenticated with Google Cloud\")"
      ],
      "metadata": {
        "id": "wupQb7rTqxkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2: Configure Upload **Settings**"
      ],
      "metadata": {
        "id": "CUw1QjNMq06q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure your GCS settings\n",
        "PROJECT_ID = 'lego-training-123456'  # ‚Üê Change this to your GCP project ID\n",
        "BUCKET_NAME = 'lego-dataset-split'  # ‚Üê Change this to your bucket name\n",
        "LOCAL_FOLDER = '/content/dataset/lego_split'  # Your local folder to upload\n",
        "GCS_DESTINATION = 'lego_split_2'  # Destination folder name in GCS bucket\n",
        "\n",
        "print(f\"üì¶ Local folder: {LOCAL_FOLDER}\")\n",
        "print(f\"‚òÅÔ∏è  GCS bucket: gs://{BUCKET_NAME}/{GCS_DESTINATION}\")"
      ],
      "metadata": {
        "id": "3jyn6__Oq5R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3: Upload to GCS (Method 1 - Using gsutil)"
      ],
      "metadata": {
        "id": "xuv5fCFBq9mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload using gsutil (fastest for large datasets)\n",
        "import os\n",
        "\n",
        "if os.path.exists(LOCAL_FOLDER):\n",
        "    print(f\"üöÄ Starting upload to gs://{BUCKET_NAME}/{GCS_DESTINATION}...\")\n",
        "    print(\"This may take a while depending on dataset size...\\n\")\n",
        "\n",
        "    # Upload with progress\n",
        "    !gsutil -m cp -r {LOCAL_FOLDER} gs://{BUCKET_NAME}/{GCS_DESTINATION}\n",
        "\n",
        "    print(\"\\n‚úÖ Upload complete!\")\n",
        "    print(f\"üìç Your dataset is now at: gs://{BUCKET_NAME}/{GCS_DESTINATION}\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Folder {LOCAL_FOLDER} not found!\")"
      ],
      "metadata": {
        "id": "s83klf_7rBlG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}